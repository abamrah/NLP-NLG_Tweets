{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB_4_Sequential_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bphECiUa9zw"
      },
      "source": [
        "# Lab 4: Sequential Data\n",
        "\n",
        "This lab is based on an assignment developed by Prof. Lisa Zhang.\n",
        "\n",
        "In this assignment, we will build a recurrent neural network to classify a SMS text message\n",
        "as \"spam\" or \"not spam\". In the process, you will\n",
        "    \n",
        "1. Clean and process text data for machine learning.\n",
        "2. Understand and implement a character-level recurrent neural network.\n",
        "3. Use torchtext to build recurrent neural network models.\n",
        "4. Understand batching for a recurrent neural network, and use torchtext to implement RNN batching.\n",
        "5. Understand how transfer learning can be applied to NLP projects.\n",
        "\n",
        "### What to submit\n",
        "\n",
        "Submit an HTML file containing all your code, outputs, and write-up\n",
        "from parts A and B. You can produce a HTML file directly from Google Colab. The Colab instructions are provided at the end of this document.\n",
        "\n",
        "**Do not submit any other files produced by your code.**\n",
        "\n",
        "Include a link to your colab file in your submission.\n",
        "\n",
        "Please use Google Colab to complete this assignment. If you want to use Jupyter Notebook, please complete the assignment and upload your Jupyter Notebook file to Google Colab for submission. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWiUqJJTa9z6"
      },
      "source": [
        "## Colab Link\n",
        "\n",
        "Include a link to your colab file here\n",
        "\n",
        "Colab Link: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFMdtipUPNdu"
      },
      "source": [
        "# PART A - Spam Detection [30 pt]\n",
        "\n",
        "In this part we will construct a LSTM model for identifying spam from non spam messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgfNOUaPa9z8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0jLI9LBa90C"
      },
      "source": [
        "## Part 1. Data Cleaning [10 pt]\n",
        "\n",
        "We will be using the \"SMS Spam Collection Data Set\" available at http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
        "\n",
        "There is a link to download the \"Data Folder\" at the very top of the webpage. Download the zip file, unzip it, and upload the file `SMSSpamCollection` to Colab.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSuF7C_Ga90E"
      },
      "source": [
        "### Part (a) [1 pt]\n",
        "\n",
        "Open up the file in Python, and print out one example of a spam SMS, and one example of a non-spam SMS.\n",
        "\n",
        "What is the label value for a spam message, and what is the label value for a non-spam message?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_IfXHeTa90F"
      },
      "source": [
        "for line in open('SMSSpamCollection'):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AukA6vMVa90d"
      },
      "source": [
        "### Part (b) [1 pt]\n",
        "\n",
        "How many spam messages are there in the data set?\n",
        "How many non-spam messages are there in the data set?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgsqyemVa90e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1WXxVt6a90h"
      },
      "source": [
        "### Part (c) [2 pt]\n",
        "\n",
        "We will be using the package `torchtext` to load, process, and batch the data.\n",
        "A tutorial to torchtext is available below. This tutorial uses the same\n",
        "Sentiment140 data set that we explored during lecture.\n",
        "\n",
        "https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8\n",
        "\n",
        "Unlike what we did during lecture, we will be building a **character level RNN**.\n",
        "That is, we will treat each **character** as a token in our sequence,\n",
        "rather than each **word**.\n",
        "\n",
        "Identify two advantage and two disadvantage of modelling SMS text\n",
        "messages as a sequence of characters rather than a sequence of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhnz8Nk-a90i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie_D0bv9a90k"
      },
      "source": [
        "### Part (d) [1 pt]\n",
        "\n",
        "We will be loading our data set using `torchtext.data.TabularDataset`. The\n",
        "constructor will read directly from the `SMSSpamCollection` file. \n",
        "\n",
        "For the data file to be read successfuly, we\n",
        "need to specify the **fields** (columns) in the file. \n",
        "In our case, the dataset has two fields: \n",
        "\n",
        "- a text field containing the sms messages,\n",
        "- a label field which will be converted into a binary label.\n",
        "\n",
        "Split the dataset into `train`, `valid`, and `test`. Use a 60-20-20 split.\n",
        "You may find this torchtext API page helpful:\n",
        "https://torchtext.readthedocs.io/en/latest/data.html#dataset\n",
        "\n",
        "Hint: There is a `Dataset` method that can perform the random split for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_Y6Puz9a90l"
      },
      "source": [
        "import torchtext\n",
        "\n",
        "text_field = torchtext.data.Field(sequential=True,      # text sequence\n",
        "                                  tokenize=lambda x: x, # because are building a character-RNN\n",
        "                                  include_lengths=True, # to track the length of sequences, for batching\n",
        "                                  batch_first=True,\n",
        "                                  use_vocab=True)       # to turn each character into an integer index\n",
        "label_field = torchtext.data.Field(sequential=False,    # not a sequence\n",
        "                                   use_vocab=False,     # don't need to track vocabulary\n",
        "                                   is_target=True,      \n",
        "                                   batch_first=True,\n",
        "                                   preprocessing=lambda x: int(x == 'spam')) # convert text to 0 and 1\n",
        "\n",
        "fields = [('label', label_field), ('sms', text_field)]\n",
        "dataset = torchtext.data.TabularDataset(\"SMSSpamCollection\", # name of the file\n",
        "                                        \"tsv\",               # fields are separated by a tab\n",
        "                                        fields)\n",
        "\n",
        "# dataset[0].sms\n",
        "# dataset[0].label\n",
        "# train, valid, test = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6nP0Ks_a90o"
      },
      "source": [
        "### Part (e) [2 pt]\n",
        "\n",
        "You saw in part (b) that there are many more non-spam messages than spam messages.\n",
        "This **imbalance** in our training data will be problematic for training.\n",
        "We can fix this disparity by duplicating spam messages in the training set,\n",
        "so that the training set is roughly **balanced**.\n",
        "\n",
        "Explain why having a balanced training set is helpful for training our neural network.\n",
        "\n",
        "Note: if you are not sure, try removing the below code and train your mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWvx9_rka90p"
      },
      "source": [
        "# save the original training examples\n",
        "old_train_examples = train.examples\n",
        "# get all the spam messages in `train`\n",
        "train_spam = []\n",
        "for item in train.examples:\n",
        "    if item.label == 1:\n",
        "        train_spam.append(item)\n",
        "# duplicate each spam message 6 more times\n",
        "train.examples = old_train_examples + train_spam * 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7eUmBEva90r"
      },
      "source": [
        "### Part (f) [1 pt]\n",
        "\n",
        "We need to build the vocabulary on the training data by running the below code.\n",
        "This finds all the possible character tokens in the training set.\n",
        "\n",
        "Explain what the variables `text_field.vocab.stoi` and `text_field.vocab.itos` represent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CQM8flKa90s"
      },
      "source": [
        "text_field.build_vocab(train)\n",
        "#text_field.vocab.stoi\n",
        "#text_field.vocab.itos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC8WVE8Ua90u"
      },
      "source": [
        "### Part (g) [1 pt]\n",
        "\n",
        "The tokens `<unk>` and `<pad>` were not in our SMS text messages.\n",
        "What do these two values represent?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_4Er7KUa90v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff5CNk7Qa90y"
      },
      "source": [
        "### Part (h) [1 pt]\n",
        "\n",
        "Since text sequences are of variable length, `torchtext` provides a `BucketIterator` data loader,\n",
        "which batches similar length sequences together. The iterator also provides functionalities to\n",
        "pad sequences automatically.\n",
        "\n",
        "Take a look at 10 batches in `train_iter`. What is the maximum length of the\n",
        "input sequence in each batch? How many `<pad>` tokens are used in each of the 10\n",
        "batches?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8N8qLWOa90y"
      },
      "source": [
        "train_iter = torchtext.data.BucketIterator(train,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwz-rOaha902"
      },
      "source": [
        "for batch in train_iter:\n",
        "    break\n",
        "    #print(len(batch))\n",
        "    #print(batch.sms)\n",
        "    #print(batch.label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7HnqP6_a904"
      },
      "source": [
        "## Part 2. Model Building [5 pt]\n",
        "\n",
        "Build a recurrent neural network model, using an architecture of your choosing. \n",
        "Use the one-hot embedding of each character as input to your recurrent network.\n",
        "Use one or more fully-connected layers to make the prediction based on your\n",
        "recurrent network output.\n",
        "\n",
        "Instead of using the RNN output value for the final token, another often used\n",
        "strategy is to max-pool over the entire output array. That is, instead of calling\n",
        "something like:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(out[:, -1, :])\n",
        "```\n",
        "\n",
        "where `self.rnn` is an `nn.RNN`, `nn.GRU`, or `nn.LSTM` module, and `self.fc` is a \n",
        "fully-connected \n",
        "layer, we use:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(torch.max(out, dim=1)[0])\n",
        "```\n",
        "\n",
        "This works reasonably in practice. An even better alternative is to concatenate the\n",
        "max-pooling and average-pooling of the RNN outputs:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "out = torch.cat([torch.max(out, dim=1)[0], \n",
        "                 torch.mean(out, dim=1)], dim=1)\n",
        "self.fc(out)\n",
        "```\n",
        "\n",
        "We encourage you to try out all these options. The way you pool the RNN outputs\n",
        "is one of the \"hyperparameters\" that you can choose to tune later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHl1p_Wwa905"
      },
      "source": [
        "# You might find this code helpful for obtaining\n",
        "# PyTorch one-hot vectors.\n",
        "\n",
        "ident = torch.eye(10)\n",
        "print(ident[0]) # one-hot vector\n",
        "print(ident[1]) # one-hot vector\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "print(ident[x]) # one-hot vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LTQ7zFka909"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKIYPl_Ba90_"
      },
      "source": [
        "## Part 3. Training [8 pt]\n",
        "\n",
        "### Part (a) [2 pt]\n",
        "\n",
        "Complete the `get_accuracy` function, which will compute the\n",
        "accuracy (rate) of your model across a dataset (e.g. validation set).\n",
        "You may modify `torchtext.data.BucketIterator` to make your computation\n",
        "faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvNfhGD6a91A"
      },
      "source": [
        "def get_accuracy(model, data):\n",
        "    \"\"\" Compute the accuracy of the `model` across a dataset `data`\n",
        "    \n",
        "    Example usage:\n",
        "    \n",
        "    >>> model = MyRNN() # to be defined\n",
        "    >>> get_accuracy(model, valid) # the variable `valid` is from above\n",
        "    \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlxlcAC1a91C"
      },
      "source": [
        "### Part (b) [2 pt]\n",
        "\n",
        "Train your model. Plot the training curve of your final model. \n",
        "Your training curve should have the training/validation loss and\n",
        "accuracy plotted periodically.\n",
        "\n",
        "Note: Not all of your batches will have the same batch size.\n",
        "In particular, if your training set does not divide evenly by\n",
        "your batch size, there will be a batch that is smaller than\n",
        "the rest. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVtf7CJCa91D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE3eRkDAa91F"
      },
      "source": [
        "### Part (c) [2 pt]\n",
        "\n",
        "Choose at least 4 hyperparameters to tune. Explain how you tuned the hyperparameters.\n",
        "You don't need to include your training curve for every model you trained.\n",
        "Instead, explain what hyperparemters you tuned, what the best validation accuracy was,\n",
        "and the reasoning behind the hyperparameter decisions you made.\n",
        "\n",
        "For this assignment, you should tune more than just your learning rate and epoch. \n",
        "Choose at least 2 hyperparameters that are unrelated to the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2GEWfDca91G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7DY56rKa91I"
      },
      "source": [
        "### Part (d) [1 pt]\n",
        "\n",
        "Before we deploy a machine learning model, we usually want to have a better understanding\n",
        "of how our model performs beyond its validation accuracy. An important metric to track is\n",
        "*how well our model performs in certain subsets of the data*.\n",
        "\n",
        "In particular, what is the model's error rate amongst data with negative labels?\n",
        "This is called the **false positive rate**.\n",
        "\n",
        "What about the model's error rate amongst data with positive labels?\n",
        "This is called the **false negative rate**.\n",
        "\n",
        "Report your final model's false positive and false negative rate across the\n",
        "validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ggbQSdba91J"
      },
      "source": [
        "# Create a Dataset of only spam validation examples\n",
        "valid_spam = torchtext.data.Dataset(\n",
        "    [e for e in valid.examples if e.label == 1],\n",
        "    valid.fields)\n",
        "# Create a Dataset of only non-spam validation examples\n",
        "valid_nospam = None # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1iRteb3a91O"
      },
      "source": [
        "### Part (e) [1 pt]\n",
        "\n",
        "The impact of a false positive vs a false negative can be drastically different.\n",
        "If our spam detection algorithm was deployed on your phone, what is the impact\n",
        "of a false positive on the phone's user? What is the impact of a false negative?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFLUOJTGa91Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gznefulsa91V"
      },
      "source": [
        "## Part 4. Evaluation [7 pt]\n",
        "\n",
        "### Part (a) [1 pt]\n",
        "\n",
        "Report the final test accuracy of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5L5D-A1a91W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hjmd8rca91Y"
      },
      "source": [
        "### Part (b) [1 pt]\n",
        "\n",
        "Report the false positive rate and false negative rate of your model across the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFiAKztJa91Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jGHtQFpa91b"
      },
      "source": [
        "### Part (c) [3 pt]\n",
        "\n",
        "What is your model's prediction of the **probability** that\n",
        "the SMS message \"machine learning is sooo cool!\" is spam?\n",
        "\n",
        "Hint: To begin, use `text_field.vocab.stoi` to look up the index\n",
        "of each character in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_2nSJq8a91b"
      },
      "source": [
        "msg = \"machine learning is sooo cool!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD1zgYJpa91f"
      },
      "source": [
        "### Part (d) [2 pt]\n",
        "\n",
        "Do you think detecting spam is an easy or difficult task?\n",
        "\n",
        "Since machine learning models are expensive to train and deploy, it is very\n",
        "important to compare our models against baseline models: a simple\n",
        "model that is easy to build and inexpensive to run that we can compare our\n",
        "recurrent neural network model against.\n",
        "\n",
        "Explain how you might build a simple baseline model. This baseline model\n",
        "can be a simple neural network (with very few weights), a hand-written algorithm,\n",
        "or any other strategy that is easy to build and test.\n",
        "\n",
        "**Do not actually build a baseline model. Instead, provide instructions on\n",
        "how to build it.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dwiiZYdvz34"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIR3Q5l0v1HP"
      },
      "source": [
        "# PART B - Transfer Learning [20 pt]\n",
        "\n",
        "In this part we will compare our earlier model with one that takes advantage of a generative RNN model to improve the prediction. There are several ways to implement transfer learning with RNNs, here we will use an approach known as ULMFiT developed by fastai. Rather than rebuilding the model from scratch, we will take advantage of the fastai library.\n",
        "\n",
        "Provided below is some helper code to get you started.\n",
        "\n",
        "#### Helper Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R-_BQyiAMoo"
      },
      "source": [
        "# install relevant libraries\n",
        "!pip install fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "316Xs5WBv0kg"
      },
      "source": [
        "# load relevant libraries\n",
        "from fastai import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os\n",
        "from fastai.text import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfoKX8tKAU4Q"
      },
      "source": [
        "# download SPAM data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
        "!unzip smsspamcollection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4vSv4Z9QxTJ"
      },
      "source": [
        "This time we will load the data using pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKPhLwlhAbv-"
      },
      "source": [
        "# set up data and verify\n",
        "df1 = pd.read_csv('SMSSpamCollection', sep='\\t',  header=None, names=['target', 'text'])\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rorC2T1yAfWY"
      },
      "source": [
        "# check distribution\n",
        "df1['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snNazefHQ3yo"
      },
      "source": [
        "Split the data into training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4WuVTDhArhc"
      },
      "source": [
        "# split the data and check dimensions\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into training and validation set\n",
        "df_trn, df_val = train_test_split(df1, stratify = df1['target'], test_size = 0.3, random_state = 999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyCkDbTRAyxk",
        "outputId": "7edacf77-44fd-4469-a153-1255f1fdc8be"
      },
      "source": [
        "df_trn.shape, df_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3900, 2), (1672, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuGx5mebBfEm"
      },
      "source": [
        "### Create the language model\n",
        "Esentially, the language model contains the structure of the language (English in this case), allowing us to quickly use in a classification model, skipping the part of learning the semantics of the language from scratch.\n",
        "\n",
        "Creating a language model from scratch can be intensive due to the sheer size of data. Instead we will download the pre-trained model, which is a neural network (NN) with an AWD_LSTM architecture. By setting pretrained = True we say to fastai to download the weights from the trained model (a corpus of 103 MM of wikipedia articles)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6yWJklsBdPp"
      },
      "source": [
        "# create pretrained language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
        "lang_mod = language_model_learner(data_lm,  arch = AWD_LSTM, pretrained = True, drop_mult=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT_aVqCRB8DJ"
      },
      "source": [
        "### Testing the language model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlZgAMGbCZXY"
      },
      "source": [
        "for i in range(5):\n",
        "  print(lang_mod.predict(\"The problem usually starts when\", n_words=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-9pK9cTCmFP"
      },
      "source": [
        "Each time we excecute the `predict`, we get a different random sentence, completed with the number of choosen words (`n_words`).\n",
        "\n",
        "Try your own sentences!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8-HUwNYCqSO"
      },
      "source": [
        "### Fine-tuning the language model\n",
        "The language model that we have \"loaded\" is great for generating wikipedia-like sentances, but here we're more interested in generating data like our email dataset. \n",
        "\n",
        "Make sure to enable GPU for this step or it make takes several hours to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z6lG13vRnbo"
      },
      "source": [
        "# fine-tune language model data\n",
        "lang_mod.fit_one_cycle(4, max_lr= 5e-02)\n",
        "lang_mod.freeze_to(-1)\n",
        "lang_mod.fit_one_cycle(3, slice(1e-2/(2.6**4), 1e-2))\n",
        "lang_mod.freeze_to(-2)\n",
        "lang_mod.fit_one_cycle(3, slice(3e-3/(2.6**4), 1e-3))\n",
        "lang_mod.unfreeze()\n",
        "lang_mod.fit_one_cycle(3, slice(3e-3/(2.6**4), 1e-3))\n",
        "\n",
        "# save language model\n",
        "lang_mod.save_encoder('my_awsome_encoder')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT-Y6pB1SrGg"
      },
      "source": [
        "### Classification model\n",
        "Now we can train a classification model that will identify spam and non-spam messages. Since we used a fastai language model, it will be easier to just continue working with the fastai library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIvfaeOfTDZV"
      },
      "source": [
        "# Classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn,  valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2fiXTCTjHh"
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sjwotSITjHi"
      },
      "source": [
        "# create the classifier\n",
        "learn_classifier = text_classifier_learner(data_clas, drop_mult=0.7, arch = AWD_LSTM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfzqId9jTjHi"
      },
      "source": [
        "# load language model\n",
        "learn_classifier.load_encoder('my_awsome_encoder')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQzxgvqSTjHi"
      },
      "source": [
        "# train classifier\n",
        "learn_classifier.lr_find()\n",
        "learn_classifier.recorder.plot(suggestion=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7boiRtwsTjHi"
      },
      "source": [
        "learn_classifier.fit_one_cycle(5, max_lr=1e-2, moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToR6na02TjHi"
      },
      "source": [
        "learn_classifier.recorder.plot_losses()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLHJl3oQTjHi"
      },
      "source": [
        "lang_mod.freeze_to(-1)\n",
        "\n",
        "learn_classifier.lr_find()\n",
        "learn_classifier.recorder.plot(suggestion=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyADkr6yTyG9"
      },
      "source": [
        "Test out the classification model on spam and non-spam examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_KKaOnrTjHj",
        "outputId": "ce8ec156-a81c-48e7-ffd2-819fbdf0848c"
      },
      "source": [
        "# predict\n",
        "learn_classifier.predict('did you buy the groceries for dinner? :)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(0), tensor(0), tensor([1.0000e+00, 3.4299e-07]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8Xv4N9STjHj",
        "outputId": "b5693d8d-775a-41b0-e6bd-7cfec20a92e6"
      },
      "source": [
        "# predict\n",
        "learn_classifier.predict('Free entry call back now')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(1), tensor(1), tensor([0.4233, 0.5767]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcUOVjveT8Xu"
      },
      "source": [
        "Next we will evaluate on all of our validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jkvU1PvTTjHj",
        "outputId": "e777a8a1-b26d-4bdd-8f94-c28339814cd9"
      },
      "source": [
        "# get predictions from validation\n",
        "valid_preds, valid_label=learn_classifier.get_preds(ds_type=DatasetType.Valid, ordered=True)\n",
        "valid_preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1672, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4UopYcrWw38"
      },
      "source": [
        "## Part 1. Evaluate Performance [10pt]\n",
        "\n",
        "### Part (a) [5pt]\n",
        "\n",
        "Implement the above helper code for spam detection. \n",
        "\n",
        "What is the accuracy obtained with ULMFiT? How does ULMFiT compare to the approach in the first part using only LSTM?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJFv4ywTWw4F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybdyEKx5Ww4F"
      },
      "source": [
        "### Part (b) [5pt]\n",
        "Provide a confusion matrix of the performance for the two models. How do they compare? Are there any qualitative differences between the performances (i.e. examine the samples for which the models differred)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuxLCHhFWw4F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9BpSLGBWw4F"
      },
      "source": [
        "## Part 2. Evaluate on New Data [10pt]\n",
        "\n",
        "### Part (a) [4pt]\n",
        "What is your model's prediction of the probability that the SMS message \"machine learning is sooo cool!\" is spam?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho0F4VMCnzXR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4FlSj_Mn2yY"
      },
      "source": [
        "### Part (b) [3 pt] \n",
        "Load 5 sample sentences from your spam mail and test it out out the two models you created. How well do they perform?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3DCyMW_n05f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "646WjsAwWw4F"
      },
      "source": [
        "### Part (c) [3pt]\n",
        "Load 5 sample sentences from your regular mail and test it out out the two models you created. How well do they perform?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OvvnW8OWw4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYwI4RmFS2RB"
      },
      "source": [
        "### Saving to HTML\n",
        "Detailed instructions for saving to HTML can be found <a href=\"https://stackoverflow.com/questions/53460051/convert-ipynb-notebook-to-html-in-google-colab/64487858#64487858\">here</a>. Provided below are a summary of the instructions:\n",
        "\n",
        "(1) download your ipynb file by clicking on File->Download.ipynb\n",
        "\n",
        "(2) reupload your file to the temporary Google Colab storage (you can access the temporary storage from the tab to the left)\n",
        "\n",
        "(3) run the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TrsqdNgS5ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fadbeb34-0b7d-4190-d837-a5ec9f276eb6"
      },
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html LAB_4_Sequential_Data.ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook TUT_4B_Generative_RNN.ipynb to html\n",
            "[NbConvertApp] Writing 602750 bytes to TUT_4B_Generative_RNN.html\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuXhlFlPTY7F"
      },
      "source": [
        "(4) the html file will be available for download in the temporary Google Colab storage\n",
        "\n",
        "(5) review the html file and make sure all the results are visible before submitting your assignment to Quercus"
      ]
    }
  ]
}